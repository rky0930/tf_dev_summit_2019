# TensorFlow Dev Summit 2019

## Day 1 - March 6th
<div class="devsite-table-wrapper"><table class="devsite-events-agenda android-dev-summit__agenda-table">
  <tbody>
    <tr style="border: none">
      <td><b>Time</b></td>
      <td><b>Subject (YouTube vidoe link)</b></td>
      <td><b>Speaker</b></td>
      <td><b><small>Text<br>Summary</small></b></td>
    </tr>
    <tr>
      <td>9:30 AM</td>
      <td><a href="https://youtu.be/b5Rs1ToD9aI">Keynote</a></td>
      <td>
        <b>Megan Kacholia</b>, Engineering Director<br>
        <b>Rajat Monga</b>, Engineering Director<br>
        <b>Kemal El Moujahid</b>, Director, Product Management<br>
        <b>Alina Shinkarsky</b>, Program Manager
      </td>
      <td></td>
    </tr>
    <tr>
      <td>9:50 AM</td>
      <td><a href="https://youtu.be/k5c-vg4rjBw">TensorFlow 2.0</a></td>
      <td>
        <b>Karmel Allison</b>, Engineering Manager<br>
        <b>Martin Wicke</b>, Software Engineer
      </td>
      <td><a href="#tensorflow-20">link</a></td>
    </tr>
    <tr>
      <td>10:15 AM</td>
      <td><a href="https://youtu.be/DKosV_-4pdQ">TensorFlow Lite</a></td>
      <td>
        <b>Pete Warden</b>, Software Engineer<br>
        <b>Raziel Alvarez</b>, Software Engineer
      </td>
      <td><a href="#tensorflow-lite">link</a></td>
    </tr>
    <tr>
      <td>10:55 AM</td>
      <td colspan="2">Break</td>
      <td></td>
    </tr>
    <tr>
      <td>12:00 PM</td>
      <td><a href="https://youtu.be/xM8sO33x_OU">New features in TensorBoard<a></td>
      <td>
        <b>Gal Oshri</b>, Product Manager
      </td>
      <td><a href="#tensorboard">link</a></td>
    </tr>
    <tr>
      <td>12:10 PM</td>
      <td><a href="https://youtu.be/Up9CvRLIIIw">Building Models with tf.function &amp; tf.autograph<a></td>
      <td>
        <b>Alexandre Passos</b>, Software Engineer
      </td>
      <td><a href="#tffunction-and-autograph">link</a></td>
    </tr>
    <tr>
      <td>12:22 PM</td>
      <td><a href="https://youtu.be/-nTe44WT0ZI">Datasets and Models</a></td>
      <td>
        <b>Ryan Sepassi</b>, Software Engineer
      </td>
      <td><a href=#tensorflow-datasets>link</a></td>
    </tr>
    <tr>
      <td>12:30 PM</td>
      <td><a href="https://youtu.be/s65BigoMV_I">Swift for TensorFlow: </br>Next-Generation Machine Learning Framework</a></td>
      <td>
        <b>Chris Lattner</b>, Distinguished Engineer<br>
        <b>Brennan Saeta</b>, Software Engineer
      </td>
      <td><a href="#swift-for-tensorflow-the-next-generation-machine-learning-framework">link</a></td>
    </tr>
    <tr>
      <td>1:00 PM</td>
      <td><a href="https://youtu.be/e_Drpr-wfAA">TensorFlow Community<a></td>
      <td>
        <b>Edd Wilder-James</b>, Open Source Strategist
      </td>
      <td></td>
    </tr>
    <tr>
      <td>1:15 PM</td>
      <td colspan="2">Lunch</td>
      <td></td>
    </tr>
    <tr>
      <td>2:35 PM</td>
      <td><a href="https://youtu.be/A5wiwT1qFjc">TensorFlow Extended (TFX): An End-to-End ML Platform</a> </br>Time stamp: start ~ to 19:51</td>
      <td>
        <b>Clemens Mewald</b>, Product Manager
      </td>
      <td></td>
    </tr>
    <tr>
      <td>2:55 PM</td>
      <td><a href="https://www.youtube.com/watch?v=A5wiwT1qFjc&feature=youtu.be&list=PLQY2H8rRoyvzoUYI26kHmKSJBedn3SQuB&t=1192">Data Preparation with TFX Data Validation</a> </br>Time stamp: 19:52 ~ end</td>
      <td>
        <b>Clemens Mewald</b>, Product Manager
      </td>
      <td></td>
    </tr>
    <tr>
      <td>3:10 PM</td>
      <td><a href="https://youtu.be/0O201IQlkxc">TFX Model Validation and TensorFlow Serving</a></td>
      <td>
        <b>Christina Greer</b>, Software Engineer
      </td>
      <td></td>
    </tr>
    <tr>
      <td>3:25 PM</td>
      <td><a href="https://youtu.be/y_qUJIfkbPs">TensorFlow Hub</a></td>
      <td>
        <b>André Susano Pinto</b>, Software Engineer
      </td>
      <td></td>
    </tr>
    <tr>
      <td>3:40 PM</td>
      <td colspan="2">Break</td>
      <td></td>
    </tr>
    <tr>
      <td>4:45 PM</td>
      <td><a href="https://youtu.be/BrwKURU-wpk">TensorFlow Probability</a></td>
      <td>
        <b>Josh Dillon</b>, Software Engineer
      </td>
      <td></td>
    </tr>
    <tr>
      <td>4:55 PM</td>
      <td><a href="https://youtu.be/-TTziY7EmUA">Reinforcement Learning in TensorFlow<a></td>
      <td>
        <b>Sergio Guadarrama</b>, Senior Software Engineer<br>
        <b>Eugene Brevdo</b>, Software Engineer
      </td>
      <td></td>
    </tr>
    <tr>
      <td>5:10 PM</td>
      <td><a href="https://youtu.be/x35pOvZBJk8">JavaScript: Writing models and </br>deploying them in the browser and Node.js</a></td>
      <td>
        <b>Yannick Assogba</b>, Front End Software Engineer<br>
        <b>Nick Kreeger</b>, Software Engineer
      </td>
      <td></td>
    </tr>
    <tr>
      <td>5:30 PM</td>
      <td><a href="https://youtu.be/8khPUtwaVaw">UniRoma: In Codice Ratio<a></td>
      <td>
        <b>Elena Nieddu</b>, UniRoma
      </td>
      <td></td>
    </tr>
  </tbody>
</table></div>

## Day 2 - March 7th
<div class="devsite-table-wrapper"><table class="devsite-events-agenda android-dev-summit__agenda-table">
  <tbody>
    <tr style="border: none">
      <td>9:50 AM</td>
      <td>Lightning Talks</td>
      <td>
        <b><a href="https://youtu.be/lNGegNreehI">Butterfly</a></b> - Nathan Silberman<br>
        <b><a href="https://youtu.be/n2MwJ1guGVQ">TensorFlow.jl (Julia)</a></b> - Jonathan Malmoud<br>
        <b><a href="https://youtu.be/Y8Nfcjg0faw">NetEase</a></b> - Huijie Lin<br>
        <b><a href="https://youtu.be/ABBnNjbjv2Q">TF Lattice</a></b> - Maya Gupta<br>
        <b><a href="https://youtu.be/bpoe33TfVAk">Alibaba</a></b> - Wei Lin<br>
        <b><a href="https://youtu.be/D1c2pi624X4">TF.text</a></b> - Mark Omernick<br>
        <b><a href="https://youtu.be/paJNSODuu3c">Uber Manifold</a></b> - Lezhi Li<br>
        <b><a href="https://youtu.be/GRMvCeIKvps">TF.js at Creative Labs</a></b> - Irene Alvarado<br>
      </td>
      <td></td>
    </tr>
    <tr>
      <td>11:15 AM</td>
      <td>Breakout sessions</td>
      <td>
        <b>2.0 and Porting Models</b><br>
        Karmel Allison, Martin Wicke, Tomer Kaftan, Alex Passos, Anna Revinskaya<br>
        <br>
        <b>TensorFlow at Scale</b><br>
        Jiri Simsa, Reed Wanderman-Milne, Penporn Koanantakool, Yuefeng Zhou<br>
        <br>
        <b>TensorFlow On-Device: Compressing, Quantizing, and Distributing</b><br>
        YC Ling, Suharsh Sivakumar, Sara Sirajuddin, Tim Davis, Pete Warden
      </td>
      <td></td>
    </tr>
    <tr>
      <td>12:00 PM</td>
      <td>Lunch</td>
      <td>
        <b>Contributors Luncheon</b> for those interested in SIGs and more<br>
        <br>
        <b>TensorFlow Extended (TFX)</b> workshop<br>
        <a href="https://github.com/rcrowe-google/TFX-DevSummit-2019">TFX Workshop  Meterials GitHub Repo</a>
      </td>
      <td></td>
    </tr>
    <tr>
      <td>1:15 PM</td>
      <td>Research and the Future</td>
      <td>
        <b><a href="https://youtu.be/e0QK5glozC8">NERSC - Exascale Deep Learning for Climate Analytics</a></b><br>
        Thorsten Kurth<br>
        <br>
        <b><a href="https://youtu.be/1YbPmkChcbo">Federated Learning</a></b><br>
        Krzysztof Ostrowski<br>
        <br>
        <b><a href="https://youtu.be/HgGyWS40g-g">Mesh TensorFlow</a></b><br>
        Noam Shazeer<br>
        <br>
        <b><a href="https://youtu.be/rlpQjnUvoKw">Sonnet 2.0</a></b><br>
        Tamara Norman, Malcolm Reynolds
      </td>
      <td></td>
    </tr>
  </tbody>
</table></div>


# Summaries in Text
### Keynote:
  - skip

### TensorFlow 2.0
  - TensorFlow 2.0 alpha realsed(since 2019/3/6)
    - pip install -U --pre tensorflow
  - What is changed: 
    - Usability:
      - tf.keras as the high-level API
      - Eager execution by default
    - Clarity:
      - Remove duplicate functionality
      - Consistant intuitive syntax across APIs
      - Compatibility throughout the TensorFlow ecosystem
    - Flexibility:
      - Full lower-level API
      - Internal ops accessible in tf.raw_ops
      - Inheritable interfaces for variables, checkpoints layers
  - How do i upgrade from 1.0 to 2.0? # "Google is now under process of converting one of the largest codebases in the world"
    - Provide migration guides and best practices
    - Provide Escape to backwords compatibility module: tf.compat.v1(contains all of the 1.x API except tf.contrib)
    - Provide conversion script: tf_upgrade_v2 # "Note that this automatic conversion it will fix it, so, it works, but it won't fix your style"
  - Timeline
    - Alpha
      - Available now
    - Next release candidate
      - In spring
      - Implementing some missing features
        - Converting libraries
        - Converting Google
      - A lots of testing and optimization
    - RC
      - Release testing
      - Integration testing
  - Progress
    - Check [Tensorflow 2.0 Project Tracker](https://github.com/orgs/tensorflow/projects/4)
  - Go build
    - pip installl -U --pre tensorflow 
    - Docs: tensorflow.org/r2.0
  - High Level APIs
    - Keras inside tensorflow: tf.keras
      - Standardizing on the keras API for building layers and models
      - Include all the power of estomators
      - You cam move from prototype to distributed training, to production serving in one go
      - In 2.0, 1.x keras model definition will run in Eager mode without any modification
      - tf.keras.optimizer.*
      - tf.keras.metrics.*
      - tf.keras.losses.*
      - tf.keras.layers.*
    - Eager mode
      - Easy to debug
      - Dynamic control
    - Unified RNN layers
      - In 2.0, there is on version of the LSTM and one version of GRU layer and they select the write operation for available devices for runtime
      - tf.keras provides an API that is easy to subclass and customize, so that user can innovate on top of the existing layers
      - User can use feature colum to parse data and feed it directly in to downstream keras layers and this feature column work both with Keras and Estimators. 
        - User can mix ans match to create reusable data input pipelines
    - Tensorboard
      - Tensorboard integration with Keras as a simple as one line
        - tf.keras.callbacks.TensorBoard(log_dir=log_dir) and Use the return value as a param of model.fit(...)
        - Performance profilling is built-in
    - Going big: tf.distribute.Strategy
      - Use Multi-GPU in simple code and Scaling efficiency is greater than 90% over multiple GPUs
    - To SavedModel and beyond
      - Easily export models for use with TF Serving, TF Lite and more
    - Comming soon: 
      - Multi-node, Multi-worker synchronous training
      - Distributing tf.keras with ParmeterServerStrategy
      - Exposing canned Estimators from the Keras API
      - Handling Very Large Models with variable partitioning
      - ... and much more ! 

### Tensorflow LITE
  - Why Tensorflow Lite ? On-device ML allows building new types of products !
    - Access to more data
    - Fast and closely knit interactions
    - Privacy preserving
  - Challenges
    - Reduced compute power
    - Limited memory
    - Battery constraints
  - Simplifying ML on-device
    - Tensorflow Lite makes these challenges much easier
  - Use cases > 2B mobile devices (Have Tensorflow Lite deployed on them in production)
    - Text - Classification, Prediction
    - Speach - Recognition, Text to Speach, Speach to Text
    - Image - Object detection, Object location, OCR, Gesture Recognition, Facial modeling, Segmentation, Clustering, Compression, Super Resolution
    - Audio - Translation, Voice Synthesis
    - Content - Voice generation, Text generation, Audio generation
  - Use case 1 - Google assistant
    - 1B + devices
      - Wide ragne of devices: High/low end, arm, x86, battery powered, plugged in, many operating systems
    - Key Speach On-Device Capabilites
      - "Hey Google" Hotword with VoiceMatch
        - Tiny memory and computation footprint running continuously
        - Extremely latency sensitive
      - On-device speech recognition
        - High computation running in shorter bursts
    - Why Did We Migrate to TFLite?
      - TensorFlow Lite meets or beats our existing libraries size and speed
      - Tensorflow Lite lays the groundwork to accelerate our models on GPUs, Edge TPUs, etc.
  - Use case 2 - NetEase youdao
    - Company introduction
      - Online Education Brand with the largest numbers of users in China (800 million Users, 22 million DAU)
    - Youdao Application with TensorFlow Lite
      - App introduction
        - Youdao Dictionary - Most popular dictionary App in China 
        - Youdao Translator - Most populary translation App in China
        - U-Dictionary - Most popular dictionary and language learning App in India
      - Detail App features
        - Conveniently look up words 
          - Camera recognize words from the images and do OCR and the translation on your devices
          - Use Tensorflow Lite to accelerate the OCR and translation services
        - Photo translation 
          - Scenarios:
            - Use camera to take a photo from the many scenarios and it will do the whole image OCR ans translate the text into another languages
            - Erase the text on the image and replace the origianl text to the translated text 
            - Replace the original text to the translated text
            - Present to users with the translations
          - Use TensorFlow Lite to accelerate the OCR and translation services
    - Why NetEase youdao choose TensorFlow Lite ?
      - OCR and Translation are very sensitive to the binary size and also computation resources and it responding time
      - To accelerate abillites on device 
      - To provide the more efficient on device inferences
  - TensorFlow Lite themes
    - Usability - Get your models up and running
      - Model conversion 
        - Steps
          - TensorFlow -> Savede Model -> TF Lite Converter -> TF Lite Model
        - failures & solutions
          - Limited ops => Tensorflow Select
            - In the pipeline(future work): TensorFlow Select + Selective Registration
          - Unsupported semantics (e.g. control-flow in RNNs) => Not yet
            - In the pipeline(future work): Control flow support (e.g. loops conditions)
        - Tensorflow Select
          - Available now 
            - Enables hundresd more ops from TensorFlow on CPU
            - Caveat: binary size increase(~6MB compressed)     
          - In the pipeline(future work)
            - Selective registration
              - Selective registration is already something user can take adavangate of TensorFlow Lite for our building ops. So, user only include in the binary the ops that user is really using. So, user don't end up increasing user's binary size unnecessarily
            - Improved performance
              - Trying to blur the of the TensorFlow ops and the Tensorflow Lite ops are. One of the key points of this is blur the performance gap that there might be between one and the other  <--- blur ?? blow ??
        - Control flow support
          - In the pipeline(future work)
            - Control flow are core to many ops(e.g RNNs) and graphs. Thus TensorFlow Lite team is adding support for:
              - Loops
              - Conditions
        - Converter 2.0
          - Follow users feedback! TensorFlow Lite team is building a new converter that will answer:
            - What went wrong ?
            - Where it went wrong ?
            - How can i fix it ?        
    - Performance - Get your models executing as fast as possible
      - Incrediable inference performance
        - CPU: Pixel2 - Single threadded CPU
        - Model: MobileNet v1
        - Performance: 
          - CPU: 124 ms
          - CPU(Quantization): 64 ms
          - GPU(Flow OpenGL 16): 16 ms
          - Edge TPU(Quatized Fixed point): 2 ms
      - Benchmarking
        - Model Benchmark tool
          - Benchmarking and profiling
            - Available
              - Support for threading
              - Per op profiling
              - Support for Android NN API
      - Acceleration by delegate
        - Edge TPU delegate
          - High performance
          - Small physical and power footprint
        - GPU delegate
          - Preview available!
            - 2-7x faster than the floating point CPU implementation
            - Adds ~250KB to binary size(Android/iOS)
            - Simple to add GPU Support in source code(just need to add few lines)
          - In the pipeline(future works)
            - Expand coverage of operations
            - Further optimize performance
            - Evolve and finalize the APIs
        - Android Neural Network API(NNAPI) delete
          - Enables hardware supported by the Android NN API
        - CPU optimazations
          - TensorFlow Lite team knows CPU deployments are important!
          - In the pipeline
            - Further optimizations on these architectures:
              - Arm
              - x86
    - Optimization - Make your models even smaller and faster
      - Quatization
        - Available 
          - Post-training quatization (CPU) - recommaned to use
            - Post-training quantization with float & fixed point
            - Great for CPU deployments!
            - Benefits:
              - 4x reduction in model sizes
              - models, which consist primarily of convolutional layers get 10~50% faster execution (CPU)
              - Fully-connected & RNN-based models get up to 3x speed-up (CPU)
            - Extremely simple to try
            - User have to validate how the accuray is affected in user's particular model. But so far, TensorFlow Lite team have seen very good numbers
            - Many of the 2B devices that above mentioned are running this way
        - In the pipeline(future work) - Even better performance on CPU, Plus enable many NPUs!
          - Keras-based quantized training (CPU/NPU)
            - Training with quantization Keras-based API
          - Post-training quantization (CPU/NPU)
            - Post-training quantization with fixed point math only
        - Quantization Steps (post-training)
          - Tensorflow(estimator or Keras) > Saved Model + Calibration Data > TF Lite Converter > TF Lite Model  
        - Quantization results: training vs post-training - Result is almost the same
          - Top 1 accuracy
            - Model | float baseline | Quantization during training | Quantization after training
            - Mobilenet v1 | 70.95% | 69.97% | 69.54%
            - Resnet v2 ___| 76.8% _| 76.7% _| 76.6%
            - Mobilenet v1 | 77.9% _| 77.5% _| 77.7%
      - Other optimizations
        - Available
          - Model optimization toolkit
        - In the pipeline(future work)
          - Keras-based connection pruning
            - Connection pruning
              - What does is mean?
                - Drop connections during training
                - Dense tensors will now be sparse (filled with zeros)
              - Benefits
                - Smaller models - Sparse tensors can be compressed
                - Faster models - Less operations to execute
            - Coming soon
              - Training with connection pruning in Keras-based API (compression benefits)
            - In the pipeline(future work)
              - Inference support for sparse models (speed-ups on CPU and selected NPUs)
            - Simple to add pruning in source code(just need to add few lines)
        - Pruning results
          - Negligible accuracy loss at 50% sparsity
          - Small accuracy loss at 75%
    - Documentation - Resources to get the most out of TensorFlow Lite
      - Docs
        - Available
          - New tensorflow.org/lite
            - Revamped TensorFlow Lite documentation with new tutorials & guides
            - Published TensorFlow Lite future roadmap
        - In the pipeplie(future work)
          - More tutorials
      - Model repository
        - Available
          - In depth sample application & tutorials for(5 models):
              - Image classification
              - Object detection
              - Pose estimation
              - Segmentation
              - Smart reply
        - In the pipeplie(future work)
          - Expand repository to many more models
    - TF Mobile Deprecated
      - Provided 6+ monthes of notice
      - Limiting developer support in favor of TensorFlow Lite
      - Still available for training on Github
    - What about Traing on device using TensorFlow Lite ?
      - Training 
        - Building many of the pieces
          - TF Select + Control Flow + Subgraphs + Variables
            - Gradient calculation
            - Forward Backward
            - Initialization
            - Storage during training
        - Nothing to announce now, but, TensorFlow Lite team working on it and thinking a lot about it
    - What about Tensorflow 2.0 ?
      - TensorFlow Lite support TensorFlow 2.0
        - SavedModel -> Tensorflow Lite
    - Before we go.. 2 last thing !
      - 1) Pretty Cool New Project by Pete Warden - MCU
        - Tiny models on tiny computers !
          - Microcontroller are everywhere
          - Speech researchers were pioneers
          - Models just tens of kilobytes
        - Why the models had to be so small ? 
          - To save battery !
          - Microcontrollers use far less power than CPUs
          - Main CPU is turned off while MCU listens
          - Only tens of kilobytes of RAM and Flash available
          - No cloud connection
        - Pete thought this approach would be widely useful
          - Open up voice interfaces to more developers
          - Work with other kinds of noisy sensor data
        - Google releasing the first experimental support for embedded platforms in tensorflow light
          - Pocket size demonstration board is showed up !
          - A prototype of a development board built by Sparkfun [link](https://www.sparkfun.com/products/15170)
            - 32-bit ARM Cortex-M4F processor with Direct Memory Access
            - 48MHz CPU clock, 96MHz with TurboSPOT™
            - Extremely low-power usage: 6uA/MHz
            - 1MB Flash
            - 384KB SRAM
            - Dedicated Bluetooth processor with BLE 5
            - Available to run on a single coin battery for many days ! 
          - Live Demo by Pete Warden
            - Say "Yes"
            - Yellow light blink
            - [Demo Video Link](https://youtu.be/DKosV_-4pdQ?t=1951)
        - Why is this useful ?
          - Running entirely on-device
          - Tiny constraints
            - It's using a 20 KB model
            - Run using less than 100KB of RAM and 80KB of Flash
          - All Open Source & Train your own model
            - https://aiyprojects.withgoogle.com/open_speech_recording
            - https://www.tensorflow.org/tutorials/sequences/audio_recognition
          - Try it for yourself!
            - https://www.sparkfun.com/products/15170
            - Designed to be portable, runs on many other platform
            - Looking forward to collaborating ! 
      - 2) Teachable Machine - On-Device Transfer Learning on the Coral Dev Board
        - What is Coral ?
          - Coral is a platform for creating products with on-device ML acceleration
          - First products features Google's Edge TPU in SBC and USB accessory forms
        - Edge TPU
          - A Google-designed AISC that lets you run inference on-device:
            - Very fast inference speed(Object detection in less than 15ms)
            - Enables greater data privacy
            - No reliance on a network connection
            - Runs inference with Tensorflow Lite
          - Enables unique workloads and new applications Like on-device real-time transfer learning
          
        - Coral Products
          - Coral Dev Board
            - A single-board computer with a removable system-on-module (SOM) featuring the Edge TPU.
            - Supported OS: Mendel Linux (derivative of Debian), Android
            - Supported Framework: TensorFlow Lite
            - Languages: Python (C++ coming soon)
            - [Datasheet](https://coral.withgoogle.com/tutorials/devboard-datasheet/)
            - [Learn More](https://coral.withgoogle.com/products/dev-board/)
          - Coral Accelerator
            - A USB accessory featuring the Edge TPU that brings ML inferencing to existing systems.
            - Supported OS: Debian Linux
            - Compatible with Raspberry Pi boards
            - Supported Framework: TensorFlow Lite
            - [Datasheet](https://coral.withgoogle.com/tutorials/accelerator-datasheet/)
            - [Learn More](https://coral.withgoogle.com/products/accelerator/)
          - Edge Training Demo
            - Three ways to do edge training:
              - k-nearest neighbors
              - Weight imprinting
              - Last layer retraining
            - Teachable Machine 
              - K-nearest neighbors approach is used
              - Live Demo by June
                - Teachable Machine showed up
                  - Edge TPU development board assembled with a camera and series of buttons
                  - Each botton corresponds with the class and lights up when the model identifes an objects from the camera
                  - The training process is done on edge device immediately
                  - Classify perfectly
                  - [Demo Video Link](https://youtu.be/DKosV_-4pdQ?t=2527)

### TensorBoard
  - What's new with TensorBoard ?
    - Summary
      - TensorBoard in Colab and Jupyter Notebook
      - Easier comparison of train and validation runs
      - Keras conceptual graph visualization
      - Hyperparameter tuning with the HParams dashboard
    - Details
      - "Tensor Board Team enables showing tensor board directly within colab and Jupyter Notebook"
        - How ?
          - Train with model.fit() and give it a tensorboard callback
          - This logged the right data to visualize in Tensor Board
        - Before this new features, User have to download the logs to local machine to visualize the data with Tensor Board
      - "Train and Validation showing up on the same charts to make it much easier to compare them in accuracy loss"
      - More flexable Graph Dashboard
      - Several APIs for using Tensor Board within notebooks that user change the height of the cell as well as list the active instances within user's collab notebook
      - Hyperparameter Tuning
        - Available in the TF 2.0 alpha
        - How to use ?
          - Several additional imports are needed
          - Define which values of the hyperparameters user want to try
            - Ex) num_units_list = [16, 32]
            - dropout_rate_list = [0.1, 0.2]
            - optimizer_list = ['adam']
          - Define matrix
            - ex) accuracy
          - Wrap the existing training code
          - Start Training !
          - The progress of traing is showed within Tensor Board in Colab(Jupyter Notebook)
            - Go to "HPARAMS" dashboard in TensorBoard Top Menu
              - TABLE VIEW
                - Each run is represented by a row
                - Each columns for each of the hyper parameters
                - Filtering and Sorting are available in the matrix
              - PARALLEL COORDINATES VIEW
              - SCATTER PLOT MATRIX VIEW

### tf.function and Autograph
  - Why graphs ? If we have graphs, 
      - We can get full program optimization on some hardware like TPU
      - We can take a model and deploy it on server, mobile devices and whatever thing you want
  - So, Just keep doing with graphs ? No
  - TensorFlow is fundamentally changing the programming model in v2.0
    - Removing the model that first add a bunch of nodes to a graph and then rely on session that run to prune things out of the graph to figure out the precise thins you want to running the correct order.
    - Replaceing it with a much simpler model based on this notion of a function
    - It's "tf.function()"
    - User will never have to use session or run anymore
  - tf.function()
    - A function is like an op
      - Just like an operation execpt one that user get to define using composition of the other operations intensive flow
      - Once have the funtion, 
        - User call it in inside another function
        - User can take it's gradient
        - User can run it on the GPU, TPU, CPU, distributed things
      - Just like how user do with any other tensorflow operation
    - Functions can be faster than eager code
      - If user look at models there are large convolutions or big matrix multiplications large reductions, it's not actually any faster becuase the eager excution is pretty fast
      - Whereas models get small and the operations get small, tf.function speed up tensorflow.
        - ex) Tenfold speed up if user used tf.funtion with tiny lstm cells of ten units
      - Functions are polymorphic
        - Tensorflow graph is very much not polymorphic
          - ex) A graph built for a float64 cannot use float32 or float16
        - but tf.function is like python code tends to be very free into the types
        - So, User just use the tf.function as normal tensorflow operation
        - the autograph build up user's code to graph and the graph run blazingly fast
        - And, It's not completely hidden, User can access to the graph that is generated
        - If user need to manipulate the graphs, user still can do it
  - State in tf.function
    - Never write tf.control_dependencies again
      - Automatic control dependencies
  - Variables in tf.function
    - Nerver use tf.global_variables_initializer again
      - User don't need to manually initialize variables
      - Non-ambiguous code is ok
      - Inializers can be path-dependent
  - Control flow in tf.function
    - Breaking up with tf.{cond, while_loop}
      - python compiler called autograph that rewrite control flow expression into faster dynamic graph code
        - How do we customize python ?
          - Operator overloading !
            - \_\_add\_\_, \_\_sub\_\_, etc
          - We can't overload \_\_if\_\_
            - Sadly, no \_\_if\_\_, \_\_while\_\_, etc
          - Autograph:
            - it overload \_\_if\_\_, \_\_while\_\_, etc
              - Tensorflow compiler called autograph that take user's python code and rewrite it in a for that lets us call \_\_if\_\_, \_\_while\_\_, etc on tensors
  - Summary
    - session.run goes away
    - tf.control_dependencies goes away
    - tf.global_variables_initilizer goes away
    - tf.cond, tf.while_loop goes away
    - Just use tf.funtion like how we would use in a normal programming language

### TensorFlow Datasets
  - It's new way to have a collection of public research datasets
  - It's on GitHub and Pypy and ready to use with tensorflow 
  - Data and Models 
    - The ML partnership
    - tf.data
      - High-performance and flexible input pipelines
      - Data is a little out of step
        - Every single dataset is little bit different
        - User is just interesed in having data in a format that sort of ready to move into TF data pipeline
        - Google and user really want that data and models to be simpatico
      - TensorFlow Datasets
        - Let's play nice
          - import tensorflow_datasets as tfds
          - train_ds = tfds.load("<NAME_OF_DATASET>/<ENCODING_TYPE>", split="train", as_superviesed=True)
          - train_ds = train_dataset.shuffle(1024).batch(128)
          - for input, targets in train_ds.repeat(10): # using with loop
          - ... 
      - class DatasetBuilder
        - Each of tf.dataset is packaged together as a datasetBuilder
          - First, it had a method called download and prepare
          - Second, as_dataset. as_dataset take those pre-processed files on disk and produces a tf.data.dataset
          - Third, Useful information. Metadata about the dataset which can be programmatically useful.
            - DatasetInfo
              - Documenting objects 
              - features (shape, class label)
              - total_num_examples
              - splits (train, test)
              - etc
      - TensorFlow Datasets support NumPy usage too
        - tfds.as_numpy(...)
          - It hide all the tensorflow from user
          - return python generator over numpy array
      - Installation
        - pip install tensorflow-datasets
        - tensorflow.org/datasets
        - httsp://github.com/tensorflow/datasets
      - 30+ datasets with more on the way
        - There is more being added every day
        - The community on github has actually gotten surprisingly active
      - Make your data famous 
        - httsp://github.com/tensorflow/datasets

### Swift for Tensorflow: The Next-Generation Machine Learning Framework
  - Swift for TensorFlow
    - TensorFlow with no boundaries!
  - Swift 
    - Modern and Cross-platform programming language
    - Designed to be easy to learn and use
    - OpenSource (swift.org)
  - Image classfication model
    - look alot like Keras
    - Code example
  - Train a model
    - Pick an optimizer and random input then pick a training loop
    - Code example
  - Demo: Basic Workflow
    - Modifying machine learning models
      - Environment
        - Google collab hosted Jupyter notebooks and It comes with Swift for TensorFlow
      - First try:
        - Initiate a model
        - Use stocastic gradient descent SDG optimizer
        - Just train a model using swift for tensorflow
        - Start training 
        - Found the loss is decreased 
      - Second try:
        - Add dense layers
        - Add skip connection
        - Re-run training loop
      - This is an example of what it's like to use Swift tensorflow to develop and iterate as you apply models to applications 
  - Swift for tensorflow was designed for researchers
    - Researchers often .. 
      - need to do more than just change models
      - change the way the archtecture fits together
      - need to define entirely new abstractions or layers
    - Writing custom layers
      - Define DoubleBiasDenseLayer
      - Code example
      - Initiate
      - Training using custom hand write training loop
    - Simulate running on a super large data parallel GPU or TPU cluster on a single machine
      - Experimenting with batch sizes
        - Custom training loop
          - Additional inner loop
          - Run forward pass
          - Take the gradients for each step and aggregate them in this grads variable
          - Simulates running on four independent accelerateors four GPUS
          - So plexable
  - No boundary: Interoperability
    - No wrappers, Just import it, then call it  
    - Demo: Interoperability
      - Seamless Python Interoperability
        - Import Tensoflow
        - Import Python
        - The Python object that allow you to import arbitray python libraries
        - ex) matplotlib.pyplot and numpy from python
        - Run the plt.plot and numpy and they just works
        - Looks like the python code but it's actually pure Swift
        - Just works seamlessly 
      - RL with OpenAI Gym
        - Import Gym
        - Define neural network
        - Use cart pole v-0 environment
        - Run 
        - Get gradient
        - Record the mean reward 
        - Train
        - It's all very simple straight forward Swift 
        - User can train using Swift TensorFlow model in an openAI gym environment using Python bridge. Totally seamless
        - User can keep train of the parameters of the rewards and plot the mean rewards as the model train using Python Numpy. Totally seamless
  - No boundary: Differentiable programming
    - Demo: Differentiable Programming
      - Differential Programming
        - annotate @differentiable then tensorflow will derive the derivative for the function
          - Just plain old double is used becuased automatic differentiation is built right into the language
      - Custom differential data types
        - @differentiable helps catch errors
        - Maginitude of point
          - Swift doesn't include a square root function because I want a good excuse for you to see the interoperability with C
          - We're actually goint to use a C's square root function that operates on doubles
          - Error occured, Why ?
            - Square root function is compiled by the C compiler and today the C compiler can't automaticcally compute deribatives for you 
          - This is great excuse to show you how to write custom gradients
          - So, create own square root function with swift
      - Demo Summary
        - How to use 
          - customization
          - custom gradients
          - custom datatypes with the language integrated automatic differentiation built into swift for TensorFlow
      - Printing out values in the backward pass
  - No boundary: Performance
    - Speedy low level performance
    - Thread-level scalability, no GIL
    - Automatic graph extraction
    - Example: AlphaGo Zero
      - Combination of three technologies
        - Deep learning
        - "Old AI" techniques: Monte Carlo Search
        - High performance TPU accelerators
      - Demo: MiniGo in Colab
        - Open-source go player inspired by deep minds alphago zero project
        - It's available on github
        - Monte Carlo tree search and the rest of mini go self play in pure Swift
  - No boundary: AI education
    - Jeremy Howard from Fast.AI
      - Fast.AI always looking to push the boundaries of what's possible with deep learning especially pushing to make recent advances more accessible
      - World's best document classifier
      - Hundreds thousands have become deep learning practitioners through Fast.AI cources
      - SOTA result with Fast.AI library
      - Announcing that Fast.AI's next course will include a big Swift component
  - Most important part is that Swift for TensorFlow is really TensorFlow. 
  - Open Source
    - https://github.com/tensorflow/swift
    - swift@tensorflow.org
  - colab
    - Works great in colab
  - v0.2 is released
    - Available now: Intrepid researchers wanted! 
    - Not ready for production yet but
      - Tensorflow swift team is very excited about 
        - Shaping future,
        - Building out,
        - Exploring new programming model. 
      - This is a great opportunity for this advanced researchers to get involved and help shape the future of tensorflow swift platform

### TensorFlow Extended (TFX): An End-to-End ML Platform 
  - TensorFlow extended (TFX): An End-to-End ML Platform
    - Figure 1: High-level component overview of a machine learning platform
  - TFX powers our most important bets and products
    - AlphaBets
    - Major Products
  - So far, we've made some of our libraries available
    - Figure 1: High-level component overview of a machine learning platform
  - ... and some of our most important partners
  - Today, we share the horizontal layers that integrate libraries in one product
  - Building Components out of Libraries
  - What makes a Component
    - Well defined config
    - Context
  - Metadata Store? That's new
    - Task-Aware Pipelines
    - Task-and Data-Aware Pipelines
  - What's in the Metadata Store ?
    - Type definitions of Artifacts and their Properties
      - E.g. Models, Data, Evaluation Metrics
    - Execution Records (Runs) of Components
      - E.g. Runtime Configuration, Inputs + Outputs
    - Lineage Tracking Across All Executions
      - E.g. To recurse back to all inputs of a specific artifact
  - List all training runs and attributes
  - Visualize lineage of a specific model
  - Visualize data a model was trained on
  - Visualize sliced eval metrics associated with a model
  - Launch TensorBoard for a specific model run
  - Launch TensorBoard to compare multiple model runs
  - Compare data statistics for multiple models
  - Examples of Metadata-Powered Functionality ** 
    - Use-cases enabled by lineage tracking
    - Compare previous model runs 
    - Carry-over state from previous models
    - Re-use previously computed outputs
  - How do we orchestrate TFX?
    - Component
    - Driver and Publisher
    - Execute
    - TFX Config
  - Bring your very own favorte orchestractor
    - AirFlow Runtime
    - Kubeflow Runtime
    - Your own runtime 
  - TFX: Putting it all together
    - Image 
  - Get started with TensorFlow Extended(TFX)
    - An End-toEnd ML Platform
    - https://github.com/tensorflow/tfx
    - https://tensorflow.org/tfx
  - TFX End-to-End Example
    - Chicago Taxi Cab Dataset
      - Features
        - Categorical
        - Bucket
        - Vocab
        - Dense Float
      - Transfomrs
      - Model (Wide+Deep)
      - Output: High tip or not
  